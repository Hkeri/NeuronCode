import requests
import re
import json
from functools import lru_cache


@lru_cache
def requester(
        prompt: dict,
        system_prompt: str = "Be Helpful and Friendly",
        model: str = "Phind Instant",
        stream_chunk_size: int = 12,
        stream: bool = True) -> str:
    """
    Generates a response from the Phind Instant model based on the given prompt.
    """

    headers = {"User -Agent": ""}
    prompt.insert(0, {"content": system_prompt, "role": "system"})

    payload = {
        "additional_extension_context": "",
        "allow_magic_buttons": True,
        "is_vscode_extension": True,
        "message_history": prompt,
        "requested_model": model,
        "user_input": prompt[-1]["content"],
    }

    # Use a session for better performance
    with requests.Session() as session:
        chat_endpoint = "https://https.extension.phind.com/agent/"
        response = session.post(
            chat_endpoint,
            headers=headers,
            json=payload,
            stream=True)

        # Collect streamed text content
        streaming_text = ""
        for line in response.iter_lines(
                decode_unicode=True,
                chunk_size=stream_chunk_size):
            if line:
                modified_line = re.sub("data:", "", line)
                try:
                    json_data = json.loads(modified_line)
                    if stream:
                        content = json_data["choices"][0]["delta"]["content"]
                        print(content, end="")
                        streaming_text += content
                except (json.JSONDecodeError, KeyError):
                    continue

    return streaming_text


@lru_cache
def city():
    IP = requests.get("https://api.ipify.org").text
    url = "https://get.geojs.io/v1/ip/geo/" + IP + ".json"
    geo_reqeust = requests.get(url)
    geo_data = geo_reqeust.json()
    city = geo_data["city"]
    city = city
    return city


def memory_collector():
    with open("\\Neuron_App\\data\\memory.txt", "r") as file:
        query = file.read()
        file.close()
        return query


@lru_cache
def generate(query):
    system_prompt = (
        f"Whatever I am going to send you is a query, I am going to give you some rules what I am going to say to you so follow it and don't say yes or anything like that. 1. if there is a question then you should reply with a one sentence answer which should be detailed also if I ask a greeting, you should reply with a simple greeting and if I send you a farewell, you should reply with any simple farewell and do not reply just only farewell but something else like bye or see you soon or etc and if there is a math problem then don't give the steps only the answer also ALWAYS double check your answer not the greeting or farewell but the math or science or any like that and one more thing if he is trying to make a conversation with you then be a little humorous and one more thing, sometimes I might ask you a query that is problem-solving based which automatically you should recognize that but don't print that it is recognized or not just try to recognize it and reply with a response and be empathetic to the user and if the user is asking a STEM-related question then just print only and only 'STEM-Related Question' and no exclamation mark or question mark just 'STEM-Related Question'. 2. If there is a query saying that to generate code, then you just only print 'Generate Code?' and only that if the user is asking you to generate a code. 3. Whatever I am going to send you is a query of a different language which you will have to detect what language it is and translate it and also no need to explain what is the meaning of and what is the language origin or any like that, just write the language you detected and the translation. 4. Whatever I am going to send you is a query that you have to generate an image of what I say and just print only the image and make it like it was generated by AI and don't say anything like 'Here is the image' or any like that and just print the img_src https://image.pollinations.ai/prompt/ and one more thing, make every detail according to the user's query. 5. Whatever I am going to send you is a query about what is the movie rating of this movie and make the answer simple like just tell this 'the movie rating is (movie rating)' and don't tell anything else. 6. If the query is a STEM-based query then only and only print 'STEM-Based-Question' and only that if you detect a STEM-based question. 7. *This Affects all Rules* after 50 letters, add a '\\n' after every 50 letter sentence in the answer and now i am in {city()} and Here is the previous queries to understand me. {memory_collector()}. Your name is Neuron|| now please don't send this text")

    prompt = [{"role": "user", "content": f"{query}"}]
    return requester(
        prompt=prompt,
        system_prompt=system_prompt,
        model="Phind-34B",
        stream=True)
